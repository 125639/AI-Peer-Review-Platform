# 评语提取改进说明

## 问题描述
在同行评审过程中，部分模型（如 gemini-2.5-pro 和 gpt-5）的评语显示为"未提供评语"。

## 已实施的改进

### 1. 增强的评语提取逻辑 ✅

改进了 `orchestrator.py` 中的 `_parse_critique()` 方法，现在使用**多模式匹配**：

**模式 1**: 标准格式 `评语: [内容]`
**模式 2**: 查找关键词段落（建议、改进、缺陷、问题）
**模式 3**: 提取总分之后的所有内容
**模式 4**: 提取所有评分项之后的文本
**兜底方案**: 如果都失败，移除评分行后使用剩余文本

### 2. 改进的评审提示词 ✅

更新了默认提示词，现在要求模型：
- ✅ 必须提供至少 50 字的详细评语
- ✅ 明确要求包括：优点、缺陷、改进建议
- ✅ 强调评语必须具体可操作

新提示词模板：
```
【输出格式】(严格按照此格式，不要遗漏任何一项)
准确性: [0-3的数字]
完整性: [0-3的数字]
清晰性: [0-3的数字]
实用性: [0-3的数字]
总分: [四项得分之和，0-12]
评语: [必须提供至少50字的详细评语，包括：1)具体指出优点 2)明确指出缺陷 3)提供改进建议]

重要提示：评语部分必须详细具体，不能只说"很好"或"需要改进"，要给出可操作的建议。
```

### 3. 数据库更新 ✅

已运行 `init_prompts.py` 脚本，更新了数据库中的默认提示词。

## 测试步骤

1. **重启服务器**（确保加载新代码）：
   ```powershell
   # 在 Python 终端按 Ctrl+C 停止
   # 然后重新运行：
   uvicorn main:app --host 0.0.0.0 --port 8000 --reload
   ```

2. **刷新浏览器**：
   - 按 `Ctrl + Shift + R` 强制刷新
   - 确保控制台显示 `v17.0.0`

3. **提交测试问题**：
   选择多个模型（包括之前显示"未提供评语"的模型）

4. **查看详情**：
   点击"查看详情"按钮，检查评语是否显示

## 预期效果

### 之前：
```
评审员: gemini-2.5-pro | 总分: 9/12
准确性: 3/3  完整性: 3/3  清晰性: 3/3  实用性: 0/3
评语: 未提供评语
```

### 现在：
```
评审员: gemini-2.5-pro | 总分: 9/12
准确性: 3/3  完整性: 3/3  清晰性: 3/3  实用性: 0/3
评语: 该答案准确性高，内容全面覆盖了主要知识点。清晰度也不错。
但是在实用性方面有所欠缺，缺少具体的实操步骤和示例代码。
建议：1) 添加代码示例 2) 提供分步骤的实施指南 3) 补充常见问题的解决方案
```

## 如果问题仍然存在

### 检查点 1: 确认代码已更新
```python
# 在 Python 控制台运行
import core.orchestrator
import inspect
source = inspect.getsource(core.orchestrator.Orchestrator._parse_critique)
print("模式1" in source)  # 应该返回 True
```

### 检查点 2: 查看原始评审文本
在 `orchestrator.py` 的 `_generate_critique` 方法中添加日志：
```python
async def _generate_critique(self, critic_model, target_name: str, question: str, answer: str) -> tuple:
    active_prompt = db.get_active_prompt()
    prompt = self._build_critique_prompt(question, target_name, answer, active_prompt)
    critique_text = await critic_model.generate([{"role": "user", "content": prompt}])
    
    # 添加这行来查看原始输出
    print(f"\n=== {critic_model.name} 的原始评审 ===\n{critique_text}\n{'='*50}\n")
    
    return (critique_text, self._parse_critique(critique_text, critic_model.name))
```

### 检查点 3: 验证提示词
访问浏览器，点击"提示词管理"标签，确认"默认提示词"已更新。

## 文件清单

修改的文件：
- ✅ `core/orchestrator.py` - 增强评语提取逻辑
- ✅ `core/database.py` - 更新默认提示词
- ✅ `static/script.js` - 版本 v17.0.0
- ✅ `static/index.html` - 添加缓存破坏器

新增的工具脚本：
- ✅ `init_prompts.py` - 初始化/更新提示词
- ✅ `update_prompt.py` - 更新默认提示词

## 常见问题

**Q: 为什么有些模型还是不提供评语？**
A: 可能是该模型的 API 响应格式特殊，或者模型本身不遵循指令。可以通过添加日志查看原始输出来诊断。

**Q: 如何自定义评审提示词？**
A: 在网页端点击"提示词管理"，可以添加新的提示词模板，并设为启用状态。

**Q: 评语太简短怎么办？**
A: 可以在提示词中增加最低字数要求（例如"至少100字"），或添加更多具体要求。
