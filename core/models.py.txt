import abc
import openai
import google.generativeai as genai
import aiohttp
import asyncio
from typing import List, Dict, Optional

# --- 抽象基类 ---
class BaseModel(abc.ABC):
    """所有AI模型的抽象基类"""
    def __init__(self, provider_config: Dict, model_name: str):
        self.name = f"{provider_config['name']}::{model_name}"
        self.provider_type = provider_config['type']
    
    @abc.abstractmethod
    async def generate(self, messages: List[Dict], session: aiohttp.ClientSession) -> str:
        """生成响应的抽象方法"""
        pass

# --- OpenAI 兼容模型 ---
class OpenAIModel(BaseModel):
    """支持OpenAI API格式的模型（包括兼容接口）"""
    def __init__(self, provider_config: Dict, model_name: str):
        super().__init__(provider_config, model_name)
        self.model_name = model_name
        self.client = openai.AsyncOpenAI(
            api_key=provider_config['api_key'],
            base_url=provider_config.get('api_base')
        )

    async def generate(self, messages: List[Dict], session: aiohttp.ClientSession) -> str:
        try:
            response = await self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.7,
                stream=False
            )
            return response.choices[0].message.content or ""
        except Exception as e:
            return f"[OpenAI API Error: {str(e)}]"

# --- Google Gemini 模型 ---
class GeminiModel(BaseModel):
    """Google Gemini模型"""
    def __init__(self, provider_config: Dict, model_name: str):
        super().__init__(provider_config, model_name)
        self.model_name = model_name
        genai.configure(api_key=provider_config['api_key'])
        self.model = genai.GenerativeModel(model_name)

    async def generate(self, messages: List[Dict], session: aiohttp.ClientSession) -> str:
        try:
            # 将OpenAI格式的消息转换为Gemini格式
            gemini_messages = []
            for msg in messages:
                role = 'user' if msg['role'] == 'user' else 'model'
                gemini_messages.append({
                    'role': role,
                    'parts': [msg['content']]
                })
            
            # 使用asyncio.to_thread在线程池中运行同步代码，避免阻塞事件循环
            response = await asyncio.to_thread(
                self.model.generate_content,
                gemini_messages,
                generation_config=genai.types.GenerationConfig(temperature=0.7)
            )
            return response.text
        except Exception as e:
            return f"[Gemini API Error: {str(e)}]"

# --- 工厂函数 ---
def create_model_instance(provider_config: Dict, model_name: str) -> Optional[BaseModel]:
    """根据服务商配置和模型名称创建模型实例。"""
    model_type = provider_config.get('type')
    if model_type == 'OpenAI':
        return OpenAIModel(provider_config, model_name)
    elif model_type == 'Gemini':
        return GeminiModel(provider_config, model_name)
    else:
        return None
