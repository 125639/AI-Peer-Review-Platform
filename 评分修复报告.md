# 评分系统问题修复报告

## 📊 问题描述

从用户截图发现：
- ✅ deepseek-chat: 10/12 评分正常
- ✅ deepseek-reasoner: 10/12 评分正常
- ❌ **gemini-2.5-pro: 0/12 所有维度都是0分**
- ✅ gpt-5: 9/12 评分正常

gemini-2.5-pro 的评语显示："的缺陷，主要集中在'完整性'上。"
这表明该模型没有按照要求的格式输出评分。

## 🔍 根本原因

gemini-2.5-pro 返回的文本**不包含评分标签**（准确性、完整性等），导致正则表达式无法匹配，所有评分默认为0。

可能的原因：
1. 模型不遵循格式指令
2. API返回被截断
3. 模型用自然语言描述而非结构化输出

## ✅ 已实施的修复

### 1. 添加详细调试日志 ✅

在 `orchestrator.py` 的 `_parse_critique()` 方法中添加了完整的调试输出：

```python
print(f"\n{'='*60}")
print(f"🔍 解析 {critic_name} 的评审输出")
print(f"{'='*60}")
print(f"原始文本 ({len(text)} 字符):\n{text[:500]}...")
print(f"{'='*60}\n")
```

现在可以在终端看到每个模型的原始输出和解析过程。

### 2. 增强评分提取 ✅

支持多种格式：
- ✅ `准确性: 2` （标准格式）
- ✅ `准确性：2` （中文冒号）
- ✅ `准确性 2` （无冒号）
- ✅ `accuracy: 2` （英文）

每个维度都会尝试多种匹配模式。

### 3. 更严格的提示词 ✅

更新了默认提示词，包含：
- 🔴 **【重要：必须严格按照指定格式输出，否则评审无效】**
- 📝 **【示例输出】** - 提供完整的格式示例
- ⚠️ **【警告】** - 明确列出不要做什么
- ✅ 要求"直接输出格式，不要添加任何前缀"

新提示词强调了4次格式要求！

### 4. 更新数据库 ✅

已运行 `init_prompts.py`，数据库中的默认提示词已更新。

## 🚀 测试步骤

### 步骤 1: 重启服务器（重要！）

在 Python 终端按 **Ctrl+C** 停止服务器，然后重新运行：

```powershell
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 步骤 2: 刷新浏览器

按 **Ctrl + Shift + R** 强制刷新浏览器。

### 步骤 3: 提交测试

1. 选择多个模型（包括 gemini-2.5-pro）
2. 提交一个测试问题
3. **观察终端输出** - 会看到类似这样的调试信息：

```
============================================================
🔍 解析 gemini-2.5-pro 的评审输出
============================================================
原始文本 (XXX 字符):
准确性: 2
完整性: 1
...
============================================================

✓ 找到准确性: 2
✓ 找到完整性: 1
✓ 找到清晰性: 3
✓ 找到实用性: 1

最终评分: 准确2 完整1 清晰3 实用1 = 7/12
```

### 步骤 4: 查看结果

点击"查看详情"按钮，检查：
- ✅ 所有模型都有评分（不再是0/12）
- ✅ 评分维度正确显示
- ✅ 评语内容完整

## 📋 预期效果对比

### 修复前：
```
评审员: gemini-2.5-pro | 总分: 0/12
准确性: 0/3  完整性: 0/3  清晰性: 0/3  实用性: 0/3
评语: 的缺陷，主要集中在'完整性'上。
```

### 修复后：
```
评审员: gemini-2.5-pro | 总分: 8/12
准确性: 2/3  完整性: 2/3  清晰性: 3/3  实用性: 1/3
评语: 该答案准确性较好，基本符合事实。完整性方面略有不足...
（至少50字的详细评语）
```

## 🔧 如果问题仍然存在

### 方案 A: 查看终端日志

重启服务器后，终端会显示每个模型的原始输出。如果看到：

```
✗ 未找到准确性
✗ 未找到完整性
...
```

说明模型仍然没有按格式输出。

### 方案 B: 为特定模型创建专用提示词

1. 在浏览器中点击"提示词管理"标签
2. 查看当前的"默认提示词"是否已更新
3. 如果某个模型持续不遵循格式，可以创建专门的提示词

### 方案 C: 使用JSON格式（未来改进）

可以考虑要求模型输出JSON格式：
```json
{
  "accuracy": 2,
  "completeness": 1,
  "clarity": 3,
  "usefulness": 1,
  "comment": "..."
}
```

这样更容易解析，但需要修改代码。

## 📂 修改的文件

- ✅ `core/orchestrator.py` - 添加调试日志，增强解析
- ✅ `core/database.py` - 更新默认提示词
- ✅ `init_prompts.py` - 更新数据库提示词
- ✅ `test_parse.py` - 评分解析测试工具

## 💡 关键改进点

1. **调试可见性** 📊
   - 现在可以看到每个模型的原始输出
   - 可以看到解析过程的每一步
   - 便于诊断问题

2. **格式容错性** 🛡️
   - 支持多种标点符号（:、：、无标点）
   - 支持中英文标签
   - 多模式匹配

3. **指令明确性** 📝
   - 提示词更加严格和明确
   - 提供具体的输出示例
   - 多次强调格式要求

## 🎯 下一步

1. **立即重启服务器**
2. **提交测试问题**
3. **查看终端日志**，确认 gemini-2.5-pro 现在输出正确格式
4. **反馈结果** - 告诉我是否还有评分为0的情况

---

**关键提醒：必须重启服务器才能加载新代码！** 🔄
