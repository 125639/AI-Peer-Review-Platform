"""
评分系统诊断和说明

## 问题分析

从截图可以看出：
- deepseek-chat: 10/12 ✅ 正常
- deepseek-reasoner: 10/12 ✅ 正常  
- gemini-2.5-pro: 0/12 ❌ 所有评分都是0
- gpt-5: 9/12 ✅ 正常

gemini-2.5-pro 的评语显示："的缺陷，主要集中在'完整性'上。"
这说明该模型返回的文本不包含任何评分标签（准确性、完整性等）。

## 可能的原因

1. **模型不遵循指令**: gemini-2.5-pro 可能忽略了格式要求
2. **API返回被截断**: 只返回了部分内容
3. **模型理解有偏差**: 可能用自然语言描述而不是结构化输出

## 解决方案

### 方案1: 添加调试日志（已实施）✅
在 orchestrator.py 中添加了详细的日志输出，可以看到原始文本

### 方案2: 更严格的提示词
在提示词中多次强调格式要求，使用更明确的指令

### 方案3: 智能评分推断
如果解析失败，尝试从自然语言中推断评分：
- 识别"优秀"、"良好"、"一般"、"较差"等描述
- 根据关键词推测分数

### 方案4: 重试机制
如果第一次返回格式不对，给模型一个"纠正"的机会

### 方案5: 使用JSON格式
要求模型输出JSON格式，更容易解析

## 下一步操作

1. **重启服务器**，查看终端输出的调试日志
2. **提交测试问题**，包含 gemini-2.5-pro
3. **查看终端**，找到 gemini-2.5-pro 的原始输出
4. **根据原始输出调整解析逻辑**

## 临时解决办法

如果某个模型持续无法正常输出格式，可以：
1. 在"提示词管理"中创建专门针对该模型的提示词
2. 或者暂时不使用该模型进行评审
